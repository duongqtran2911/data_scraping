import os

import pandas as pd
import datetime
from datetime import datetime, timezone
from pymongo import MongoClient
import uuid
from datetime import datetime
import numpy as np
import json
import re
import unicodedata
import logging
from fuzzywuzzy import process
from sympy.codegen.ast import continue_

from get_coordinate_guland import action_open_guland_driver


# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
log_dir = "logs_status_coordinate"
os.makedirs(log_dir, exist_ok=True)

# ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file log
log_path = os.path.join(log_dir, "status_coordinate-2-2025-(2).log")

# T·∫°o logger ri√™ng cho ·ª©ng d·ª•ng
app_logger = logging.getLogger("app_logger1")
app_logger.setLevel(logging.INFO)

# ƒê·∫£m b·∫£o logger n√†y kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi c√°c logger kh√°c
app_logger.propagate = False

# Th√™m handler n·∫øu ch∆∞a c√≥
if not app_logger.handlers:
    file_handler = logging.FileHandler(log_path, mode="a", encoding="utf-8")
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    app_logger.addHandler(file_handler)

# Find the first row index containing a specific keyword in any column
def find_row_index_containing(df, keyword):
    norm_keyword = normalize_string(keyword)
    for i, row in df.iterrows():
        row_strs = row.astype(str).apply(normalize_string)
        if row_strs.str.contains(norm_keyword, case=False, na=False).any():
            return i
    return None


# Find where comparison table begins (looks for 'ord' codes like C1, C2, ...)
def find_comparison_table_start(df):
    for i, row in df.iterrows():
        if row.astype(str).str.match(r"C\d+", na=False).any():
            return i-3  # Adjusting to get the header row
    return None


# Find the indices of metadata
def find_meta_data(df, indicator_text="th·ªùi ƒëi·ªÉm th·∫©m ƒë·ªãnh gi√°"):
    # Detect the raw table end by locating the second occurrence of "Th·ªùi ƒëi·ªÉm th·∫©m ƒë·ªãnh gi√°"
    # indicator_text = "th·ªùi ƒëi·ªÉm th·∫©m ƒë·ªãnh gi√°"  # lowercase for matching
    indicator_indices = []

    for idx, row in df[[1]].iterrows():
        for val in row:
            if isinstance(val, str) and indicator_text in val.lower():
                indicator_indices.append(idx)
    return indicator_indices


# Find the last row of the raw data table by scanning downward for known markers like:
def find_raw_table_end(df, second_eval_row=None):
    """
    Find the last row of the raw data table by scanning downward for known markers like:
    'h√¨nh ·∫£nh th√¥ng tin quy ho·∫°ch', 'h√¨nh ·∫£nh tin rao', 'link'
    """
    target_keywords = ["h√¨nh ·∫£nh th√¥ng tin quy ho·∫°ch", "h√¨nh ·∫£nh tin rao", "link"]
    
    last_match_index = None

    for i in range(len(df)):
        first_cell = str(df.iloc[i, 1]).strip().lower()
        for keyword in target_keywords:
            if keyword in first_cell:
                last_match_index = i
    
    if last_match_index is not None:
        return last_match_index
    
    # fallback: if no match found, return a conservative guess
    return second_eval_row - 4 if second_eval_row else None


# Check if the value is a valid ord cell
def is_valid_ord(value):
    """
    Check if the ord cell looks like a valid comparison field code.
    """
    if pd.isna(value):
        return True  # continuation rows have empty ord
    value = str(value).strip().upper()
    return bool(re.match(r"^[A-E]\d{0,1}$", value)) or value in ["A", "B", "C", "D"]


# Check if a value is numeric
def is_numeric_like(x):
    try:
        return isinstance(x, (int, float)) or str(x).replace(',', '').replace('.', '').replace('-', '').isdigit()
    except:
        return False


# Find the last row of the comparison table in the DataFrame
def find_comparison_table_end(df):
    """
    Find the last row of the comparison table in the DataFrame.
    """
    ord_col = df.columns[0]

    for i in reversed(df.index):
        ord_val = df.at[i, ord_col]
        row_values = df.iloc[i, 1:]  # skip STT + ord column
        if is_valid_ord(ord_val):
            # Check if the row contains any numeric value in other columns
            if row_values.apply(lambda x: isinstance(x, (int, float)) or str(x).replace(',', '').replace('.', '').isdigit()).any():
                return i
    raise ValueError("Comparison table end not found.")


# Function that detects human notations and converts them to numbers
def parse_human_number(text):
    """
    Parse a string that might contain informal human-readable numbers like:
    - "2ty" => 2,000,000,000
    - "2ty7" => 2,700,000,000
    """
    if isinstance(text, (int, float)):
        return text  # s·ªë th·∫≠t, kh√¥ng x·ª≠ l√Ω th√™m

    if not isinstance(text, str):
        return None

    text = text.lower().replace(',', '').replace('ƒë·ªìng', '').strip()

    # N·∫øu text l√† chu·ªói s·ªë r√µ r√†ng, th√¨ chuy·ªÉn tr·ª±c ti·∫øp
    if text.isdigit():
        return int(text)

    # Match full-form human numbers like '2ty7', '2 ty 7', '26.5ty'
    match = re.search(r'(\d+(?:\.\d+)?)(?:\s*ty\s*(\d)?)?', text)

    if match:
        billion = float(match.group(1))
        hundred_million = match.group(2)
        if hundred_million and hundred_million.isdigit():
            value = int(billion * 1e9 + int(hundred_million) * 1e8)
        else:
            value = int(billion * 1e9)
        return value

    # Fallback: extract first number
    match = re.search(r'\d[\d.]*', text)
    if match:
        try:
            return float(match.group(0).replace('.', '').replace(',', ''))
        except ValueError:
            return None

    return None



# Convert a string to a float, handling various formats
def smart_parse_float(s, log_missing=False):
    """
    Extract and convert a float from a string or raw input.
    
    If `log_missing=True`, raise ValueError when:
    - The field is missing (None)
    - A number cannot be parsed from the input

    :param s: input value (string or float-like)
    :param field_name: optional field label for error context
    :param entry_id: optional ID for traceability
    :param log_missing: if True, raise error instead of returning None or NaN
    :return: float value, np.nan, or raises error if log_missing is True
    """
    # If truly missing (field not present)
    if s is None or pd.isna(s):
        if log_missing:
            raise ValueError(f"[MISSING] Required field is missing.\n")
        return np.nan

    # If already numeric (float/int), return directly
    if isinstance(s, (int, float)):
        return float(s)

    s = str(s).strip().lower()

    if "ch∆∞a bi·∫øt" in s:
        return np.nan

    # Match the first valid number in a messy string
    number_pattern = r"(\d{1,3}(?:[\.,]\d{3})*(?:[\.,]\d+)?|\d+)"
    match = re.search(number_pattern, s)

    if not match:
        if log_missing:
            raise ValueError(f"[UNPARSABLE] Cannot extract number from '{s}' in field.\n")
        return np.nan

    number_str = match.group(1)

    # Normalize based on decimal/thousand separator
    if "," in number_str and "." in number_str:
        if number_str.rfind(",") > number_str.rfind("."):
            number_str = number_str.replace(".", "").replace(",", ".")
        else:
            number_str = number_str.replace(",", "")
    elif "," in number_str and "." not in number_str:
        number_str = number_str.replace(",", ".")
    else:
        number_str = number_str.replace(",", "")

    try:
        return float(number_str)
    except Exception:
        if log_missing:
            raise ValueError(f"[ERROR] Failed to convert '{s}' to float.\n")
        return np.nan



# Normalize a string by removing accents and collapsing whitespace
def normalize_string(s):
    if not isinstance(s, str):
        return ""
    s = unicodedata.normalize("NFKD", s)  # remove accents
    s = ''.join(c for c in s if not unicodedata.combining(c))
    s = re.sub(r"\s+", " ", s)  # collapse all whitespace
    return s.strip().lower()


# Re-import necessary module after state reset
def normalize_att(attr):
    if not isinstance(attr, str):
        return attr
    attr = attr.strip().lower()
    replacements = {
        # comparison table
        "y·∫øu t·ªë kh√°c (n·∫øu c√≥)": "y·∫øu t·ªë kh√°c",
        "y·∫øu t·ªë kh√°c": "y·∫øu t·ªë kh√°c",
        'gi√° th·ªã tr∆∞·ªùng (gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng/m¬≤/nƒÉm)': 'gi√° th·ªã tr∆∞·ªùng (gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng/m¬≤)',
        'gi√° th·ªã tr∆∞·ªùng \n(gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng/m¬≤)': 'gi√° th·ªã tr∆∞·ªùng (gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng/m¬≤)',
        'gi√° th·ªã tr∆∞·ªùng \n(gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng)': 'gi√° th·ªã tr∆∞·ªùng (gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng/m¬≤)',
        'gi√° th·ªã tr∆∞·ªùng \n(gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) \n(ƒë·ªìng)': 'gi√° th·ªã tr∆∞·ªùng (gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng/m¬≤)',
        'gi√° th·ªã tr∆∞·ªùng (gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng)': 'gi√° th·ªã tr∆∞·ªùng (gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng/m¬≤)',
        'd√¢n c∆∞, kinh doanh': "d√¢n c∆∞",
        "chi·ªÅu d√†i": "chi·ªÅu d√†i (m)",
        "chi·ªÅu r·ªông": "chi·ªÅu r·ªông (m)",

        "chi·ªÅu s√¢u": "chi·ªÅu s√¢u (m)",

        "chi·ªÅu r·ªông gi√°p m·∫∑t ƒë∆∞·ªùng (m)": "ƒë·ªô r·ªông m·∫∑t ti·ªÅn (m)",
        "chi·ªÅu r·ªông gi√°p m·∫∑t ti·ªÅn ƒë∆∞·ªùng (m)": "ƒë·ªô r·ªông m·∫∑t ti·ªÅn (m)",
        "chi·ªÅu r·ªông ti·∫øp gi√°p m·∫∑t ti·ªÅn ƒë∆∞·ªùng (m)": "ƒë·ªô r·ªông m·∫∑t ti·ªÅn (m)",
        "chi·ªÅu r·ªông m·∫∑t ti·ªÅn ti·∫øp gi√°p ƒë∆∞·ªùng(m)": "ƒë·ªô r·ªông m·∫∑t ti·ªÅn (m)",
        "chi·ªÅu r·ªông m·∫∑t ti·ªÅn ti·∫øp gi√°p ƒë∆∞·ªùng (m)": "ƒë·ªô r·ªông m·∫∑t ti·ªÅn (m)",
        "chi·ªÅu r·ªông ti·∫øp gi√°p m·∫∑t ti·ªÅn (m)": "ƒë·ªô r·ªông m·∫∑t ti·ªÅn (m)",

        # raw table
        "ƒë·ªãa ch·ªâ": "ƒë·ªãa ch·ªâ t√†i s·∫£n",

        "quy m√¥ di·ªán t√≠ch (m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ quy ho·∫°ch l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ quy ho·∫°ch l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch (m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi v√† quy ho·∫°ch c√¢y xanh)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch (m¬≤)\n(ƒë√£ tr·ª≠ l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ quy ho·∫°ch l·ªô gi·ªõi ƒë·∫•t nn)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",

        "quy m√¥ di√™n t√≠ch (m¬≤)\n(trong gcn qsdƒë)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ qhlg)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch (m¬≤) (ƒë√£ tr·ª´ l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch(m¬≤) (ƒë√£ tr·ª´ l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch cln (m¬≤) (ƒë√£ tr·ª´ l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t n√¥ng nghi·ªáp thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",

        "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ch∆∞a tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t n√¥ng nghi·ªáp thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ l·ªô gi·ªõi quy ho·∫°ch)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",

        "quy m√¥ di·ªán t√≠ch (m¬≤) \n(ƒë√£ tr·ª´ l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch (m¬≤)\n(theo di·ªán t√≠ch th·ª±c t·∫ø)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch (ƒë√£ tr·ª´ l·ªô gi·ªõi) (m¬≤)\n(ƒë√£ tr·ª´ quy ho·∫°ch l·ªô gi·ªõi)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch th√¥ng thu·ª∑ (m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch th√¥ng th·ªßy(m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",

        "di·ªán t√≠ch (m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "di·ªán t√≠ch s√†n (th√¥ng th·ªßy) (m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "di·ªán t√≠ch s√†n": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "di·ªán t√≠ch s√†n s·ª≠ d·ª•ng (tim t∆∞·ªùng) (m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "di·ªán t√≠ch s√†n s·ª≠ d·ª•ng (m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",
        "quy m√¥ di√™n t√≠ch tim t∆∞·ªùng (m¬≤)": "quy m√¥ di·ªán t√≠ch (m¬≤)\n(ƒë√£ tr·ª´ ƒë·∫•t thu·ªôc quy ho·∫°ch l·ªô gi·ªõi)",

        "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤/nƒÉm)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t odt (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t cln (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t ont (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t hnk (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t luc (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t cln (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t odt (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t odt(ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t ont (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t luc (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t hnk (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t ont(ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t cln(ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t luc(ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t skc ƒë·∫øn ng√†y 01/01/2046 (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° cƒÉn h·ªô theo di·ªán t√≠ch th√¥ng th·ªßy (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t n√¥ng nghi·ªáp ƒë√£ tr·ª´ ph·∫ßn quy ho·∫°ch l·ªô gi·ªõi (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t skc, th·ªùi h·∫°n ƒë·∫øn ng√†y 20/12/2054 (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",

        "gi√° ƒë·∫•t tmdv, th·ªùi h·∫°n ƒë·∫øn ng√†y 09/01/2067 (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t luc/bhk (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t tmdv (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t tmdv, th·ªùi h·∫°n ƒë·∫øn ng√†y 09/01/2067 (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "gi√° ƒë·∫•t skc (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t n√¥ng nghi·ªáp (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",
        "ƒë∆°n gi√° ƒë·∫•t ·ªü (ƒë·ªìng/m¬≤)": "gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)",

        # 2025
        "gi√° tr·ªã ƒë·∫•t odt (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t ont(ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t ont (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t cln (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t cln(ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t rsx (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t rsx(ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t tmd (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",

        # 2024
        "gi√° tr·ªã ƒë·∫•t nn (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t nn vt1 (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t luk(ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t hnk (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t odt(ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",

        "gi√° tr·ªã ƒë·∫•t luc (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",
        "gi√° tr·ªã ƒë·∫•t lua (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",

        "gi√° tr·ªã ƒë·∫•t bhk (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",

        # 5/2024
        "gi√° tr·ªã ƒë·∫•t ƒë√£ tr·ª´ ph·∫ßn quy ho·∫°ch l·ªô gi·ªõi (ƒë·ªìng)": "gi√° tr·ªã ƒë·∫•t (ƒë·ªìng)",

        "gi√° rao b√°n (ƒë·ªìng) (kh√¥ng c√≥ vat):": "gi√° rao b√°n (ƒë·ªìng)",
    }
    return replacements.get(attr, attr)

# Get the value of landPrice from raw data table
def get_land_price_raw(d, field="Gi√° ƒë·∫•t (ƒë·ªìng/m¬≤)"):
    val = smart_parse_float(d.get(normalize_att(field), None))
    return val

# Get the value of landPrice from comparison data table
def get_land_price_pct(d, field=('A', normalize_att('Gi√° th·ªã tr∆∞·ªùng (Gi√° tr∆∞·ªõc ƒëi·ªÅu ch·ªânh) (ƒë·ªìng/m¬≤)'))):
    return smart_parse_float(d[field])

# Match indices of reference percentages to raw data
def match_idx(ref_pcts, ref_raws):
    matched_idx = []  
    used_indices = set()

    for ref_pct in ref_pcts:
        pct_price = get_land_price_pct(ref_pct)
        diffs = [
            abs(get_land_price_raw(ref_raw) - pct_price)
            if i not in used_indices and pd.notna(get_land_price_raw(ref_raw)) else np.inf
            for i, ref_raw in enumerate(ref_raws)
        ]

        best_idx = int(np.argmin(diffs))
        matched_idx.append(best_idx)
        used_indices.add(best_idx)

    for i, idx in enumerate(matched_idx):
        print(f"ref_pcts[{i}] matched with ref_raws[{idx}]")

    idx_matches = dict(enumerate(matched_idx))
    return idx_matches

# Convert DMS (Degrees, Minutes, Seconds) to Decimal Degrees
def convert_dms_to_decimal(dms_str):
    match = re.match(r"(\d+)¬∞(\d+)'([\d.]+)\"?([NSEW])", dms_str.strip())
    if not match:
        return None
    degrees, minutes, seconds, direction = match.groups()
    decimal = float(degrees) + float(minutes) / 60 + float(seconds) / 3600
    if direction in ['S', 'W']:
        decimal *= -1
    return decimal

# Function to get the location from the info string
# H√†m ch√≠nh ƒë·ªÉ l·∫•y th√¥ng tin v·ªã tr√≠ (c·∫£i ti·∫øn)
def get_info_location(info, address, driver1, driver2 ,file_path):
    """
    H√†m l·∫•y th√¥ng tin v·ªã tr√≠ t·ª´ t·ªça ƒë·ªô ho·∫∑c ƒë·ªãa ch·ªâ

    Args:
        info: Th√¥ng tin t·ªça ƒë·ªô (chu·ªói)
        location: ƒê·ªãa ch·ªâ (ph√≤ng h·ªù khi kh√¥ng c√≥ t·ªça ƒë·ªô)

    Returns:
        ƒê·ªëi t∆∞·ª£ng GeoJSON Point ho·∫∑c None
    """
    # Ki·ªÉm tra t·ªça ƒë·ªô ƒë·∫ßu v√†o tr∆∞·ªõc
    if pd.notna(info) and info is not None and str(info).strip() != "":
        info_str = str(info).strip()

        # Tr∆∞·ªùng h·ª£p 1: ƒë·ªãnh d·∫°ng lat, lon ti√™u chu·∫©n (VD: 10.97, 108.22)
        if "," in info_str and all(char not in info_str for char in "¬∞'\""):
            try:
                lat, lon = info_str.split(",")
                return {
                    "type": "Point",
                    "coordinates": [float(lon.strip()), float(lat.strip())]  # MongoDB c·∫ßn [longitude, latitude]
                }
            except Exception as e:
                print(f"‚ùå L·ªói khi ph√¢n t√≠ch t·ªça ƒë·ªô ti√™u chu·∫©n: {e}")

        # Tr∆∞·ªùng h·ª£p 2: ƒë·ªãnh d·∫°ng DMS (VD: 10¬∞58'10.4"N 108¬∞13'46.8"E)
        if "¬∞" in info_str:
            try:
                dms_parts = info_str.split()
                if len(dms_parts) == 2:
                    lat_decimal = convert_dms_to_decimal(dms_parts[0])
                    lon_decimal = convert_dms_to_decimal(dms_parts[1])
                    return {
                        "type": "Point",
                        "coordinates": [lon_decimal, lat_decimal]
                    }
            except Exception as e:
                print(f"‚ùå L·ªói khi ph√¢n t√≠ch t·ªça ƒë·ªô DMS: {e}")

    # Tr∆∞·ªùng h·ª£p 3: N·∫øu kh√¥ng c√≥ t·ªça ƒë·ªô tr·ª±c ti·∫øp, th·ª≠ d√πng ƒë·ªãa ch·ªâ
    if address and str(address).strip() != "":
        log_message = f"‚ÑπÔ∏è Kh√¥ng c√≥ t·ªça ƒë·ªô trong d·ªØ li·ªáu. ƒêang s·ª≠ d·ª•ng ƒë·ªãa ch·ªâ: {address}"
        print("\n‚ÑπÔ∏è Kh√¥ng c√≥ t·ªça ƒë·ªô trong d·ªØ li·ªáu. ƒêang s·ª≠ d·ª•ng ƒë·ªãa ch·ªâ:" + address)
        app_logger.info(file_path)
        app_logger.info(log_message)
        # app_logger.info(f" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n")
        # address_infor = parse_location_info(address)
        return action_open_guland_driver(address,driver1,driver2,file_path)



    # N·∫øu t·∫•t c·∫£ c√°c ph∆∞∆°ng ph√°p th·∫•t b·∫°i
    return None


# Function to get the purpose and area from the info string
def get_info_purpose(info):
    if not isinstance(info, str) or not info.strip():
        return info, np.nan
    res = []
    
    # Split by newline or semicolon
    parts = re.split(r"[\n;]", info)

    for part in parts:
        if ":" in part:
            try:
                name, area = part.split(":", 1)
                area_clean = area.strip().lower().replace("m¬≤", "").replace("m2", "")

                # Fix number formatting
                area_clean = area_clean.replace(".", "").replace(",", ".")  # remove thousand sep, fix decimal

                match = re.search(r"[\d.]+", area_clean)
                area_val = float(match.group()) if match else np.nan

                res.append({
                    "name": name.strip(),
                    "area": area_val
                })
            except Exception as e:
                print(f"‚ö†Ô∏è Could not parse part '{part}' in purpose field: {e}")
        else:
            res.append({
                "name": part.strip(),
                "area": np.nan
            })
    return res


# Function to get the purpose and area from the info string
def get_info_unit_price(info):
    """
    Extracts the first float-like number from a string, removing thousand separators (dots) 
    and converting to float. Returns np.nan if no valid number found.
    """
    if not isinstance(info, str):
        return np.nan
    
    # Search for a number with optional dot thousands separators (e.g., 1.234.567)
    match = re.search(r'\d{1,3}(?:\.\d{3})*(?:,\d+)?|\d+(?:,\d+)?', info)
    
    if match:
        num_str = match.group()
        # Remove dot separators and convert comma to decimal (European format)
        num_str = num_str.replace('.', '').replace(',', '.')
        try:
            return float(num_str)
        except ValueError:
            return np.nan
    return np.nan


def get_max_width(width):
    
    if pd.isna(width):
        return np.nan
    
    if not isinstance(width, str):
        return float(width)  # n·∫øu l√† s·ªë th√¨ tr·∫£ v·ªÅ lu√¥n

    # Lo·∫°i b·ªè d·∫•u ph·∫©y ki·ªÉu '24,33' th√†nh '24.33'
    width = width.replace(',', '.')

    # Regex ƒë·ªÉ t√¨m gi√° tr·ªã sau c·ª•m "n·ªü h·∫≠u"
    match = re.search(r"n·ªü h·∫≠u\s*([0-9.]+)", width, flags=re.IGNORECASE)
    if match:
        try:
            return float(match.group(1))
        except ValueError:
            return None

    # N·∫øu kh√¥ng c√≥ "n·ªü h·∫≠u", c·ªë g·∫Øng l·∫•y gi√° tr·ªã ƒë·∫ßu ti√™n l√†m max_width lu√¥n
    match_fallback = re.search(r"([0-9.]+)", width)
    if match_fallback:
        try:
            return float(match_fallback.group(1))
        except ValueError:
            return np.nan

    return np.nan


def normalize_unicode(text):
    if not isinstance(text, str):
        text = str(text)
    return unicodedata.normalize("NFKC", text).strip().lower()

def get_facade_info(width_raw, location_info):
    width_str = normalize_unicode(width_raw)
    if pd.isna(width_str) or width_str == "" or width_str == "nan":
        return {"has_facade": False, "value": np.nan}
    location_str = normalize_unicode(location_info)

    # Denial keywords ‚Üí explicitly no facade
    deny_keywords = ["kh√¥ng c√≥ m·∫∑t ti·ªÅn", "h·∫ªm", "m·∫∑t h·∫≠u", "kh√¥ng ti·∫øp gi√°p", "n·ªü h·∫≠u"]
    if any(kw in width_str for kw in deny_keywords) or any(kw in location_str for kw in deny_keywords):
        return {"has_facade": False, "value": np.nan}

    # Positive facade signals ‚Äî expanded
    strong_positive_patterns = [
        r"\bm·∫∑t\s*ti·ªÅn\b",
        r"\bm·∫∑t\s*ƒë∆∞·ªùng\b",
        r"\bm·∫∑t\s*ti·ªÅn\s*ƒë∆∞·ªùng\b",
        r"\bm·∫∑t\s*ph·ªë\b",
        r"\bgi√°p\s*ƒë∆∞·ªùng\b",
        r"\btr·ª•c\s*ƒë∆∞·ªùng\b",
        r"\bƒë∆∞·ªùng\s*l·ªõn\b",
        r"\bqu·ªëc\s*l·ªô\b"
    ]

    for pattern in strong_positive_patterns:
        if re.search(pattern, location_str):
            return {"hasFacade": True, "value": np.nan}

    # Regex match from width_str: '1.96m m·∫∑t ti·ªÅn'
    match = re.search(r'([\d,\.]+)\s*m[^,\n]*?(m·∫∑t\s*ti·ªÅn)', width_str)
    if match:
        try:
            value = float(match.group(1).replace(',', '.'))
            return {"hasFacade": True, "value": value}
        except ValueError:
            pass

    # Fallback: get first number if nothing else matched
    match = re.search(r'([\d,\.]+)\s*m', width_str)
    if match:
        try:
            value = float(match.group(1).replace(',', '.'))
            return {"hasFacade": True, "value": value}
        except ValueError:
            pass

    # Default: can't detect
    return {"hasFacade": False, "value": np.nan}

# function to dynamically assign 'chi·ªÅu s√¢u' to missing field
def assign_dimensions(width, height, depth, has_facade):
    if width and height:
        return width, height
    if not width and height and depth:
        return depth, height
    if width and not height and depth:
        return width, depth
    if not width and not height and depth:
        return None, depth
    if not width and has_facade and depth:
        return None, depth
    return width, height


def fuzzy_get(entry, target_key, default = np.nan, threshold=70):
    if not entry:
        return default

    keys = list(entry.keys())
    match, score = process.extractOne(target_key, keys)

    # In ra th√¥ng tin so s√°nh
    print(f"üîç T√¨m ki·∫øm: '{target_key}'")
    print(f"   ‚û§ T√¨m th·∫•y: '{match}' (ƒê·ªô t∆∞∆°ng ƒë·ªìng: {score}%)")

    if score >= threshold:
        value = entry.get(match)
        if pd.notna(value) and str(value).strip() != "":
            print(f"   ‚úÖ Gi√° tr·ªã: {value}")
            print(f"   {'=' * 50}")
            return value
        else:
            print(f"   ‚ö†Ô∏è  Gi√° tr·ªã r·ªóng ho·∫∑c NaN")
            print(f"   {'=' * 50}")
    else:
        print(f"   ‚ùå ƒê·ªô t∆∞∆°ng ƒë·ªìng th·∫•p ({score}% < {threshold}%)")
        print(f"   {'=' * 50}")

    return default

